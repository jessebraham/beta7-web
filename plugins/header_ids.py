import re

from bs4 import BeautifulSoup
from pelican import signals

from plugins import find_html_files


def add_header_ids(pelican):
    """
    Find all headers (h1-h6) elements within <article> tags, and set their 'id'
    attributes to a slugified version of the header text.

    :param pelican: the Pelican instance
    """
    for filename in find_html_files(pelican):
        with open(filename, "r") as f:
            soup = BeautifulSoup(f.read(), "html.parser")

        article = soup.find("article")
        if article is None:
            continue

        headers = article.find_all(re.compile("^h[1-6]$"))
        for header in headers:
            # If the class list contains 'title' or 'subtitle', skip it.
            if set(header.get("class", [])) & {"title", "subtitle"}:
                continue
            header["id"] = slugify(header.text)

        with open(filename, "w") as f:
            f.write(str(soup))


def slugify(text):
    """
    Remove any invalid characters from the text, de-duplicate spaces, and then
    replace any remaining spaces with dashes. Return the resulting string.

    :param str text: the text in which to slugify

    :return str: the resulting slug
    """
    slug = re.sub(r"[^a-z0-9\s\-]", "", text.lower())
    slug = re.sub(r"\s+", " ", slug)
    slug = re.sub(r"\s", "-", slug.strip())
    return slug


def register():
    """
    Once all HTML files have been generated by pelican, set the 'id' attributes
    of all relevant headers within articles.
    """
    signals.finalized.connect(add_header_ids)
